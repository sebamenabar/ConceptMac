{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T15:59:21.839775Z",
     "start_time": "2019-08-22T15:59:21.808515Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T15:59:22.620521Z",
     "start_time": "2019-08-22T15:59:22.601990Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T15:59:28.335769Z",
     "start_time": "2019-08-22T15:59:26.345410Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchsummaryX import summary\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from mac import MACNetwork\n",
    "from utils import load_vocab\n",
    "from datasets import ClevrDataset, collate_fn as whole_collate_fn, QOnlyDataset, qonly_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:41:45.935458Z",
     "start_time": "2019-08-22T17:41:45.871564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPU_ID': '-1',\n",
       " 'CUDA': False,\n",
       " 'WORKERS': 4,\n",
       " 'TRAIN': {'FLAG': True,\n",
       "  'LEARNING_RATE': 0.0001,\n",
       "  'BATCH_SIZE': 64,\n",
       "  'MAX_EPOCHS': 25,\n",
       "  'SNAPSHOT_INTERVAL': 5,\n",
       "  'WEIGHT_INIT': 'xavier_uniform',\n",
       "  'CLIP_GRADS': True,\n",
       "  'CLIP': 8,\n",
       "  'MAX_STEPS': 4,\n",
       "  'EALRY_STOPPING': True,\n",
       "  'PATIENCE': 5,\n",
       "  'VAR_DROPOUT': False},\n",
       " 'DATASET': {'DATA_DIR': '/Users/sebamenabar/Documents/datasets/CLEVR/data'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T15:59:28.417314Z",
     "start_time": "2019-08-22T15:59:28.338677Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code/config.py:83: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "from config import cfg_from_file, __C, cfg\n",
    "\n",
    "cfg_from_file('cfg/local.yml')\n",
    "__C.CUDA = False\n",
    "__C.GPU_ID = '-1'\n",
    "vocab = load_vocab(cfg)\n",
    "# cfg.TRAIN.RECV_OBJECTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:00:00.967852Z",
     "start_time": "2019-08-22T16:00:00.238817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MACNetwork(cfg=cfg, max_step=4, vocab=vocab)\n",
    "model.load_state_dict(torch.load('/Users/sebamenabar/Documents/vanilla_mac.pth', map_location='cpu')['model'])\n",
    "# model(b['image'], b['question'], b['question_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:00:13.635579Z",
     "start_time": "2019-08-22T16:00:10.189949Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = QOnlyDataset(\n",
    "    data_dir='/Users/sebamenabar/Documents/datasets/CLEVR/data',\n",
    "    # img_dir='/Users/sebamenabar/Documents/datasets/CLEVR/CLEVR_v1.0/images/',\n",
    "    # scenes_json='/Users/sebamenabar/Documents/TAIA/individual/sm/data/clevr/train/scenes.json',\n",
    "    # raw_image=True,\n",
    "    split='train',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:00:16.768606Z",
     "start_time": "2019-08-22T16:00:16.724261Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_q(model, question, question_len):\n",
    "    embed = model.input_unit.encoder_embed(question)\n",
    "    embed = model.input_unit.embedding_dropout(embed)\n",
    "    embed = nn.utils.rnn.pack_padded_sequence(embed, question_len, batch_first=True)\n",
    "\n",
    "    contextual_words, (question_embedding, _) = model.input_unit.encoder(embed)\n",
    "    if model.input_unit.bidirectional:\n",
    "        question_embedding = torch.cat([question_embedding[0], question_embedding[1]], -1)\n",
    "    question_embedding = model.input_unit.question_dropout(question_embedding)\n",
    "\n",
    "    contextual_words, _ = nn.utils.rnn.pad_packed_sequence(contextual_words, batch_first=True)\n",
    "    \n",
    "    return question_embedding, contextual_words\n",
    "\n",
    "def idxs_to_q(questions, vocab):\n",
    "    return [\n",
    "        ' '.join([\n",
    "            vocab[idx.item()] for idx in question if idx.item() !=0\n",
    "        ]) for question in questions\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:00:19.985977Z",
     "start_time": "2019-08-22T16:00:19.941895Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cw_attention(model, question, context):\n",
    "    ret = []\n",
    "    _question = model.mac.control.control_input(question)\n",
    "    \n",
    "    for step in range(model.mac.max_step):\n",
    "        control = model.mac.control.control_input_u[step](_question)\n",
    "        control = torch.unsqueeze(control, 1)\n",
    "        interactions = control * context\n",
    "\n",
    "        logits = model.mac.control.attn(interactions)\n",
    "\n",
    "        attn = torch.softmax(logits, 1)\n",
    "        \n",
    "        ret.append(attn)\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:00:35.189460Z",
     "start_time": "2019-08-22T16:00:35.157619Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=ds, batch_size=32, shuffle=False,\n",
    "                                       num_workers=2, drop_last=False, collate_fn=qonly_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:02:09.768618Z",
     "start_time": "2019-08-22T16:00:35.820903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6034bfc5d6c646dcb4031bb36a2ad3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21875), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_words = []\n",
    "question_embeddings = []\n",
    "question_lengths = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, b in tqdm(enumerate(loader), total=len(loader)):\n",
    "        qembs, cws = forward_q(model, b['question'], b['question_length'])\n",
    "        \n",
    "        context_words.append(cws)\n",
    "        question_embeddings.append(qembs)\n",
    "        question_lengths.append(b['question_length'])\n",
    "        \n",
    "        if i >= 1000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:10:59.275208Z",
     "start_time": "2019-08-22T17:10:59.226475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 1001)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context_words), len(question_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:12.819150Z",
     "start_time": "2019-08-22T17:11:00.232219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184f85e9480d4d07aa3ef1650d8bee4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attentions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for qembs, cws in tqdm(zip(question_embeddings, context_words), total=len(question_embeddings)):\n",
    "        attentions.append(get_cw_attention(model, qembs, cws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:13.193047Z",
     "start_time": "2019-08-22T17:11:12.825236Z"
    }
   },
   "outputs": [],
   "source": [
    "_context_words = []\n",
    "for cws in context_words:\n",
    "    _context_words += [t.squeeze(0) for t in cws.split(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:13.538724Z",
     "start_time": "2019-08-22T17:11:13.197836Z"
    }
   },
   "outputs": [],
   "source": [
    "_question_embeddings = []\n",
    "for qembs in question_embeddings:\n",
    "    _question_embeddings += [t.squeeze(0) for t in qembs.split(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:15.295397Z",
     "start_time": "2019-08-22T17:11:13.542881Z"
    }
   },
   "outputs": [],
   "source": [
    "_attentions = []\n",
    "for attn in attentions:\n",
    "    for attn1, attn2, attn3, attn4 in zip(*attn):\n",
    "        _attentions.append(torch.stack((attn1, attn2, attn3, attn4)).squeeze(2))\n",
    "        # print(torch.stack((attn1, attn2, attn3, attn4)).size())\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:15.337139Z",
     "start_time": "2019-08-22T17:11:15.297883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32032 32032 32032\n",
      "torch.Size([30, 512]) torch.Size([512]) torch.Size([4, 30])\n"
     ]
    }
   ],
   "source": [
    "print(len(_context_words), len(_question_embeddings), len(_attentions))\n",
    "print(_context_words[0].size(), _question_embeddings[0].size(), _attentions[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:20.079368Z",
     "start_time": "2019-08-22T17:11:15.343268Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (cw, qemb, attn) in enumerate(zip(_context_words, _question_embeddings, _attentions)):\n",
    "    non_pad = cw.sum(dim=1) != 0\n",
    "    _context_words[i] = _context_words[i][non_pad]\n",
    "    _attentions[i] = _attentions[i][:, non_pad]\n",
    "\n",
    "    # print(non_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:20.132822Z",
     "start_time": "2019-08-22T17:11:20.084737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32032 32032 32032\n",
      "torch.Size([29, 512]) torch.Size([512]) torch.Size([4, 29])\n"
     ]
    }
   ],
   "source": [
    "print(len(_context_words), len(_question_embeddings), len(_attentions))\n",
    "print(_context_words[1].size(), _question_embeddings[1].size(), _attentions[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:21.011048Z",
     "start_time": "2019-08-22T17:11:20.141621Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = list(zip(_context_words, _attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:21.067575Z",
     "start_time": "2019-08-22T17:11:21.014457Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_pad(sequences, batch_first=True, padding_value=0):\n",
    "    max_size = sequences[0].size()\n",
    "    trailing_dims = max_size[1:]\n",
    "    max_len = max([s.size(0) for s in sequences])\n",
    "    \n",
    "    if batch_first:\n",
    "        out_dims = (len(sequences), max_len) + trailing_dims\n",
    "    else:\n",
    "        out_dims = (max_len, len(sequences)) + trailing_dims\n",
    "\n",
    "    out_tensor = sequences[0].data.new(*out_dims) # .fill_(padding_value)\n",
    "    for i, tensor in enumerate(sequences):\n",
    "        length = tensor.size(0)\n",
    "        # use index notation to prevent duplicate references to the tensor\n",
    "        if batch_first:\n",
    "            out_tensor[i, :length, ...] = tensor\n",
    "            if length < max_len:\n",
    "                out_tensor[i, length:, ...] = (1 - tensor.sum(dim=0)) / (max_len - length)\n",
    "            else:\n",
    "                out_tensor[i] = torch.softmax(out_tensor[i], dim=0)\n",
    "        else:\n",
    "            out_tensor[:length, i, ...] = tensor\n",
    "            if length < max_len:\n",
    "                out_tensor[length:, i, ...] = (1 - tensor.sum(dim=0)) / (max_len - length)\n",
    "            else:\n",
    "                out_tensor[i] = torch.softmax(out_tensor[i], dim=0)\n",
    "\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:21.124796Z",
     "start_time": "2019-08-22T17:11:21.070129Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    cws = torch.nn.utils.rnn.pad_sequence([b[0] for b in batch], batch_first=True)\n",
    "    attns = custom_pad([b[1].t() for b in batch], batch_first=True)\n",
    "\n",
    "    return cws, attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:21.178122Z",
     "start_time": "2019-08-22T17:11:21.130716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 25625 Val size: 6407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25632, 6432)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(ds) * 0.8)\n",
    "print('Train size:', train_size, 'Val size:', len(ds) - train_size)\n",
    "\n",
    "train_loader = DataLoader(ds[:train_size], batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(ds[train_size:], batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "len(train_loader) * 32 , len(val_loader) * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:21.245137Z",
     "start_time": "2019-08-22T17:11:21.183701Z"
    }
   },
   "outputs": [],
   "source": [
    "def step(model, optimizer, loader, train=True, bar=None, step=0):\n",
    "    total_loss = 0.\n",
    "    total_samples = 0\n",
    "    total_ndcg = 0.\n",
    "\n",
    "    model.train(train)\n",
    "    \n",
    "    loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "    \n",
    "    \n",
    "    with torch.set_grad_enabled(train):\n",
    "        # for b in loader:\n",
    "        lbar = tqdm(loader, total=len(loader))\n",
    "        for b in lbar:\n",
    "        \n",
    "            ret = model(b[0]).squeeze(2)\n",
    "            \n",
    "            \n",
    "            loss = loss_fn(torch.log_softmax(ret, dim=1), b[1][:,:,step])\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "            # pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_samples += b[0].size(0)\n",
    "    \n",
    "            ndcg = calc_ndcg(ret.detach().cpu().numpy(), b[1][:,:,step], k=5)\n",
    "            total_ndcg += ndcg * b[0].size(0)\n",
    "    \n",
    "            if train:\n",
    "                lbar.set_postfix(train_loss=total_loss / total_samples, train_ndcg=total_ndcg / total_samples)\n",
    "            else:\n",
    "                lbar.set_postfix(val_loss=total_loss / total_samples, val_ndcg=total_ndcg / total_samples)\n",
    "    \n",
    "    return total_loss / total_samples, total_ndcg / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:21:01.553154Z",
     "start_time": "2019-08-22T17:11:31.183988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ STEP 0 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa95f1dc4463440689921ccbf6d32585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8effe628ccfd4b94a1a6ce7c72bcb9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=801), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c4f4dac0954cabb27c1d356d72120b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train loss: 0.004443228411383745 Val loss: 0.0037066052662418285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b82c3b3e4743e1b93bbf36ff6646a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=801), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df77f5759bb4ecd86af0d8b3db92b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ STEP 1 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce91265662884c3688e08647af5f4eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a7b776661949c896e77adb14da9021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=801), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8dbb3f8d521431a97ebd7e730a739e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train loss: 0.006734322998581863 Val loss: 0.0047644713304242645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef20e3b2fdc46e9aadda6c68167b707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=801), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cd2d03e2d34e15ab6c2cd3e053f7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ STEP 2 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a531ed5719c411e905fd0ea3e16c762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1938cf0fba40c8b17da9c34f579348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=801), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a6091e1f1a4287a176c3a7dd909f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train loss: 0.004785724133689229 Val loss: 0.0032633835490806363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce01a199b0a480c825f8f31e248acd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=801), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87371b5b07e0455a85ff6c1a91ed2436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ STEP 3 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70248d16e3bd41f5a8b244f0795af4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a501d1af91fe4918bde4e5d9726f9543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=801), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3255821c15b405ab6be38d70c53e619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train loss: 0.004928564643569109 Val loss: 0.0037830763212860848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec54dfe003a46b6a3d89ce6267a719c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=801), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e22ef2e9f334e278593a95ec2034641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {}\n",
    "epochs = 2\n",
    "\n",
    "for s in range(4):\n",
    "    pred_model = nn.Sequential(\n",
    "        nn.Linear(512, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1),\n",
    "    )\n",
    "    models[s] = pred_model\n",
    "    \n",
    "    optimizer = torch.optim.Adam(pred_model.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "    loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "    print(f'------ STEP {s} ------')\n",
    "    ebar = tqdm(range(epochs))\n",
    "    for epoch in ebar:\n",
    "        train_loss, train_ndcg = step(pred_model, optimizer, train_loader, train=True, step=s)\n",
    "        val_loss, val_ndcg = step(pred_model, optimizer, val_loader, train=False, step=s)\n",
    "\n",
    "        ebar.set_postfix(train_loss=train_loss, val_loss=val_loss, train_ndcg=train_ndcg, val_ndcg=val_ndcg)\n",
    "        scheduler.step(val_loss)\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch', epoch, 'Train loss:', train_loss, 'Val loss:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:22:31.154137Z",
     "start_time": "2019-08-22T17:22:31.112767Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({key: m.state_dict() for key, m in models.items()}, '/Users/sebamenabar/Documents/attn_preds.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:11:26.417003Z",
     "start_time": "2019-08-22T17:11:26.355957Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Information Retrieval metrics\n",
    "Useful Resources:\n",
    "http://www.cs.utexas.edu/~mooney/ir-course/slides/Evaluation.ppt\n",
    "http://www.nii.ac.jp/TechReports/05-014E.pdf\n",
    "http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "http://hal.archives-ouvertes.fr/docs/00/72/67/60/PDF/07-busa-fekete.pdf\n",
    "Learning to Rank for Information Retrieval (Tie-Yan Liu)\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def mean_reciprocal_rank(rs):\n",
    "    \"\"\"Score is reciprocal of the rank of the first relevant item\n",
    "    First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n",
    "    Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
    "    >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.61111111111111105\n",
    "    >>> rs = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.5\n",
    "    >>> rs = [[0, 0, 0, 1], [1, 0, 0], [1, 0, 0]]\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.75\n",
    "    Args:\n",
    "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Mean reciprocal rank\n",
    "    \"\"\"\n",
    "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "\n",
    "\n",
    "def r_precision(r):\n",
    "    \"\"\"Score is precision after all relevant documents have been retrieved\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    >>> r = [0, 0, 1]\n",
    "    >>> r_precision(r)\n",
    "    0.33333333333333331\n",
    "    >>> r = [0, 1, 0]\n",
    "    >>> r_precision(r)\n",
    "    0.5\n",
    "    >>> r = [1, 0, 0]\n",
    "    >>> r_precision(r)\n",
    "    1.0\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        R Precision\n",
    "    \"\"\"\n",
    "    r = np.asarray(r) != 0\n",
    "    z = r.nonzero()[0]\n",
    "    if not z.size:\n",
    "        return 0.\n",
    "    return np.mean(r[:z[-1] + 1])\n",
    "\n",
    "\n",
    "def precision_at_k(r, k):\n",
    "    \"\"\"Score is precision @ k\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    >>> r = [0, 0, 1]\n",
    "    >>> precision_at_k(r, 1)\n",
    "    0.0\n",
    "    >>> precision_at_k(r, 2)\n",
    "    0.0\n",
    "    >>> precision_at_k(r, 3)\n",
    "    0.33333333333333331\n",
    "    >>> precision_at_k(r, 4)\n",
    "    Traceback (most recent call last):\n",
    "        File \"<stdin>\", line 1, in ?\n",
    "    ValueError: Relevance score length < k\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Precision @ k\n",
    "    Raises:\n",
    "        ValueError: len(r) must be >= k\n",
    "    \"\"\"\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k] != 0\n",
    "    if r.size != k:\n",
    "        raise ValueError('Relevance score length < k')\n",
    "    return np.mean(r)\n",
    "\n",
    "\n",
    "def average_precision(r):\n",
    "    \"\"\"Score is average precision (area under PR curve)\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
    "    >>> delta_r = 1. / sum(r)\n",
    "    >>> sum([sum(r[:x + 1]) / (x + 1.) * delta_r for x, y in enumerate(r) if y])\n",
    "    0.7833333333333333\n",
    "    >>> average_precision(r)\n",
    "    0.78333333333333333\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Average precision\n",
    "    \"\"\"\n",
    "    r = np.asarray(r) != 0\n",
    "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
    "    if not out:\n",
    "        return 0.\n",
    "    return np.mean(out)\n",
    "\n",
    "\n",
    "def mean_average_precision(rs):\n",
    "    \"\"\"Score is mean average precision\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n",
    "    >>> mean_average_precision(rs)\n",
    "    0.78333333333333333\n",
    "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0]]\n",
    "    >>> mean_average_precision(rs)\n",
    "    0.39166666666666666\n",
    "    Args:\n",
    "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Mean average precision\n",
    "    \"\"\"\n",
    "    return np.mean([average_precision(r) for r in rs])\n",
    "\n",
    "\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> dcg_at_k(r, 1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 1, method=1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 2)\n",
    "    5.0\n",
    "    >>> dcg_at_k(r, 2, method=1)\n",
    "    4.2618595071429155\n",
    "    >>> dcg_at_k(r, 10)\n",
    "    9.6051177391888114\n",
    "    >>> dcg_at_k(r, 11)\n",
    "    9.6051177391888114\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Discounted cumulative gain\n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> ndcg_at_k(r, 1)\n",
    "    1.0\n",
    "    >>> r = [2, 1, 2, 0]\n",
    "    >>> ndcg_at_k(r, 4)\n",
    "    0.9203032077642922\n",
    "    >>> ndcg_at_k(r, 4, method=1)\n",
    "    0.96519546960144276\n",
    "    >>> ndcg_at_k([0], 1)\n",
    "    0.0\n",
    "    >>> ndcg_at_k([1], 2)\n",
    "    1.0\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Normalized discounted cumulative gain\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max\n",
    "\n",
    "def calc_ndcg(pred, gt, k=5, method=1):\n",
    "    # pred nparray WITH softmax\n",
    "    count = 0\n",
    "    total = 0.\n",
    "    \n",
    "    sorted_pred = (-pred).argsort(axis=1)\n",
    "    for i, sample in enumerate(sorted_pred):\n",
    "        curr = ndcg_at_k(gt[i, sample], k=k, method=method)\n",
    "        total += curr\n",
    "        count += 1\n",
    "        \n",
    "        # print(curr, gt[i, sample])\n",
    "        \n",
    "    return total / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_k([0.05] * 20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_k([0.5, 0.3, 0.2, 0.1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_k([0.4, 0.5, 0.05, 0.05], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_k([0.25, 0.25, 0.25, 0.25], k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6079646887731703"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_k([0.1, 0.05, 0.05, 0.8], k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array([0.3, 0.1, 0.5])\n",
    "gt = np.array([0.1, 0.2, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7, 0.1, 0.2])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt[np.argsort(-pred, )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9616786482850547"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_k(gt[np.argsort(-pred, )], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_model(b[0]).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9, 13, 26,  ..., 12,  4, 11],\n",
       "        [11, 12, 10,  ...,  3,  7,  8],\n",
       "        [ 9, 14, 26,  ...,  7, 12,  6],\n",
       "        ...,\n",
       "        [ 0, 20, 26,  ..., 18,  6,  9],\n",
       "        [ 8,  9,  2,  ...,  4,  5,  6],\n",
       "        [10, 14, 25,  ..., 12,  5,  6]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-pred).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9, 13, 26,  ...,  4, 11, 12],\n",
       "        [11, 12, 19,  ...,  3,  9,  8],\n",
       "        [ 9, 14, 26,  ...,  7, 11, 12],\n",
       "        ...,\n",
       "        [ 0, 20, 11,  ..., 18, 17,  9],\n",
       "        [ 8,  2,  9,  ...,  5,  3,  6],\n",
       "        [10, 14,  3,  ..., 12, 13,  6]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-b[1][:,:,0]).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 38])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1][:,:,0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 0,  ..., 1, 0, 1],\n",
       "        [1, 1, 1,  ..., 1, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 0,  ..., 1, 0, 1],\n",
       "        [1, 0, 0,  ..., 0, 0, 1],\n",
       "        [1, 1, 0,  ..., 1, 0, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-pred).argsort() == (-b[1][:,:,0]).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 24, 21, 23, 25, 10, 20, 26, 11,  0, 13, 34, 14,  9,  1, 35, 36,\n",
       "       37, 27,  2, 33, 15,  3,  5, 12,  8,  4,  6,  7, 31, 32, 19, 16, 28,\n",
       "       18, 30, 17, 29])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-pred.softmax(dim=1).cpu().detach().numpy()).argsort(axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 38])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1][:,:,0][:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 24, 21, 23, 25, 10, 20, 26, 11,  0, 13, 34, 14,  9,  1, 35, 36, 37,\n",
       "        27,  2, 33, 15,  3,  5, 12,  8,  4,  6,  7, 31, 32, 19, 16, 28, 18, 30,\n",
       "        17, 29])"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-pred.softmax(dim=1).detach()).argsort()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 38)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1][:,:,0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22, 24, 21,  ..., 30, 17, 29],\n",
       "        [ 7,  9,  8,  ..., 14,  5,  4],\n",
       "        [27, 28, 26,  ..., 11,  9, 13],\n",
       "        ...,\n",
       "        [ 4, 18,  2,  ..., 16, 12, 17],\n",
       "        [12, 16, 13,  ...,  5,  4,  2],\n",
       "        [11, 15, 12,  ...,  5,  2,  3]])"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-pred.softmax(dim=1).detach()).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6142980774040249"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_k([0.1, 0.1, 0.1, 0.1, 0.6], k=5, method=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9976750697978618 tensor([3.3479e-01, 2.4326e-01, 9.4054e-02, 1.1488e-01, 8.9872e-02, 1.8376e-02,\n",
      "        1.3426e-02, 2.2863e-02, 1.6301e-02, 9.2898e-03, 3.9664e-03, 5.7711e-03,\n",
      "        1.5857e-03, 3.5235e-03, 3.4244e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.7526e-03, 2.7234e-03, 2.2329e-03, 6.7731e-04, 7.0492e-04, 4.9589e-04,\n",
      "        3.0534e-03, 8.4697e-04, 1.0258e-03, 3.2900e-04, 4.6015e-04, 3.9638e-04,\n",
      "        5.3188e-04, 6.8161e-04, 2.8981e-04, 1.1153e-03, 9.6075e-04, 4.8343e-04,\n",
      "        1.9040e-04, 6.6829e-04])\n",
      "0.9912203350330319 tensor([0.2669, 0.1131, 0.0716, 0.1152, 0.0893, 0.0378, 0.0420, 0.0033, 0.0377,\n",
      "        0.0620, 0.0257, 0.0166, 0.0093, 0.0059, 0.0029, 0.0079, 0.0050, 0.0113,\n",
      "        0.0029, 0.0019, 0.0021, 0.0010, 0.0060, 0.0035, 0.0102, 0.0042, 0.0061,\n",
      "        0.0009, 0.0067, 0.0035, 0.0035, 0.0035, 0.0035, 0.0007, 0.0062, 0.0041,\n",
      "        0.0030, 0.0030])\n",
      "0.9993238875533926 tensor([5.5919e-01, 2.6426e-01, 7.5054e-02, 8.2902e-02, 1.2917e-02, 5.2201e-04,\n",
      "        7.3350e-05, 5.6486e-05, 1.5803e-04, 5.5113e-04, 6.8682e-05, 1.3335e-03,\n",
      "        2.1191e-04, 2.1191e-04, 2.1191e-04, 2.1191e-04, 2.1191e-04, 2.1191e-04,\n",
      "        2.1191e-04, 3.3290e-04, 5.1075e-04, 1.1983e-04, 2.4362e-05, 5.9609e-05,\n",
      "        4.9808e-05, 2.0854e-05, 4.9266e-05, 3.8121e-05, 1.4445e-05, 2.4096e-05,\n",
      "        2.6280e-05, 2.2434e-05, 1.4580e-05, 4.0217e-05, 4.7039e-06, 5.4374e-05,\n",
      "        5.9930e-06, 2.4510e-05])\n",
      "0.9165492293274208 tensor([2.8728e-01, 4.4490e-01, 8.8679e-02, 8.3444e-02, 1.6909e-02, 2.0646e-02,\n",
      "        3.3581e-03, 1.3097e-02, 1.1276e-02, 4.8437e-03, 2.9514e-03, 9.9979e-04,\n",
      "        1.0047e-03, 3.6773e-03, 1.0297e-04, 1.3424e-03, 1.3424e-03, 1.3424e-03,\n",
      "        1.3424e-03, 1.3424e-03, 1.3424e-03, 1.3424e-03, 1.3424e-03, 1.1377e-03,\n",
      "        6.5822e-04, 7.3445e-04, 8.8244e-05, 1.2947e-04, 6.1739e-04, 6.1770e-04,\n",
      "        4.7213e-04, 2.4875e-04, 1.4521e-04, 2.5864e-04, 3.1522e-04, 1.1402e-04,\n",
      "        2.8144e-04, 2.6485e-04])\n",
      "0.9992546433567155 tensor([5.6735e-01, 3.4178e-01, 3.8332e-02, 4.7186e-02, 8.7891e-04, 2.3802e-04,\n",
      "        2.3802e-04, 2.3802e-04, 2.3802e-04, 2.3802e-04, 2.3802e-04, 2.3802e-04,\n",
      "        2.3802e-04, 2.3802e-04, 2.3802e-04, 2.3802e-04, 2.3802e-04, 2.3802e-04,\n",
      "        3.1432e-04, 7.1279e-05, 6.4024e-05, 1.8963e-04, 1.4152e-04, 7.1743e-05,\n",
      "        7.9209e-05, 1.0385e-04, 3.7227e-05, 3.8661e-05, 3.8106e-05, 2.1077e-05,\n",
      "        4.2364e-05, 2.2007e-05, 1.9901e-05, 3.4366e-05, 1.0800e-05, 6.6152e-05,\n",
      "        6.1923e-06, 4.4868e-06])\n",
      "0.9965557419346437 tensor([4.9581e-01, 3.4177e-01, 6.1037e-02, 8.1509e-02, 7.3844e-04, 4.0148e-03,\n",
      "        2.0544e-03, 6.6301e-04, 6.6301e-04, 6.6301e-04, 6.6301e-04, 6.6301e-04,\n",
      "        6.6301e-04, 6.6301e-04, 6.6301e-04, 6.6301e-04, 6.6301e-04, 6.6301e-04,\n",
      "        6.6301e-04, 6.6301e-04, 6.6301e-04, 6.6301e-04, 5.9608e-04, 5.4622e-04,\n",
      "        2.1436e-04, 2.4561e-04, 2.0311e-04, 2.0381e-04, 8.0038e-05, 2.0077e-04,\n",
      "        7.7313e-05, 5.6261e-05, 4.5862e-05, 2.1865e-04, 6.0605e-05, 4.1395e-05,\n",
      "        1.2073e-04, 2.0660e-04])\n",
      "1.0 tensor([0.0805, 0.0533, 0.0417, 0.0327, 0.0303, 0.0289, 0.0289, 0.0289, 0.0289,\n",
      "        0.0289, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289,\n",
      "        0.0289, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289, 0.0147, 0.0253, 0.0203,\n",
      "        0.0294, 0.0224, 0.0207, 0.0134, 0.0130, 0.0136, 0.0089, 0.0114, 0.0088,\n",
      "        0.0055, 0.0048])\n",
      "0.9423596607826618 tensor([0.0528, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385,\n",
      "        0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385,\n",
      "        0.0385, 0.0385, 0.0416, 0.0158, 0.0167, 0.0185, 0.0485, 0.0080, 0.0058,\n",
      "        0.0090, 0.0187, 0.0061, 0.0061, 0.0073, 0.0034, 0.0021, 0.0026, 0.0017,\n",
      "        0.0015, 0.0014])\n",
      "1.0 tensor([0.0894, 0.0597, 0.0499, 0.0398, 0.0318, 0.0271, 0.0271, 0.0271, 0.0271,\n",
      "        0.0271, 0.0271, 0.0271, 0.0271, 0.0271, 0.0271, 0.0271, 0.0271, 0.0271,\n",
      "        0.0271, 0.0271, 0.0271, 0.0271, 0.0271, 0.0271, 0.0271, 0.0297, 0.0167,\n",
      "        0.0223, 0.0250, 0.0216, 0.0127, 0.0121, 0.0140, 0.0090, 0.0084, 0.0046,\n",
      "        0.0060, 0.0047])\n",
      "0.9878888248452025 tensor([0.1211, 0.0561, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294,\n",
      "        0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294,\n",
      "        0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0342, 0.0179, 0.0180, 0.0254,\n",
      "        0.0210, 0.0166, 0.0137, 0.0117, 0.0150, 0.0127, 0.0105, 0.0036, 0.0018,\n",
      "        0.0012, 0.0014])\n",
      "0.9989763889034589 tensor([0.2025, 0.0638, 0.0288, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294,\n",
      "        0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294,\n",
      "        0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0294, 0.0176, 0.0073,\n",
      "        0.0059, 0.0022, 0.0057, 0.0034, 0.0038, 0.0009, 0.0028, 0.0034, 0.0026,\n",
      "        0.0016, 0.0018])\n",
      "1.0 tensor([0.2498, 0.1489, 0.1479, 0.0181, 0.0181, 0.0181, 0.0181, 0.0181, 0.0181,\n",
      "        0.0181, 0.0181, 0.0181, 0.0181, 0.0181, 0.0181, 0.0181, 0.0181, 0.0181,\n",
      "        0.0181, 0.0181, 0.0181, 0.0181, 0.0181, 0.0181, 0.0181, 0.0169, 0.0055,\n",
      "        0.0073, 0.0104, 0.0039, 0.0024, 0.0016, 0.0014, 0.0015, 0.0010, 0.0012,\n",
      "        0.0005, 0.0005])\n",
      "0.9830629648135428 tensor([0.1419, 0.0710, 0.0220, 0.0297, 0.0297, 0.0297, 0.0297, 0.0297, 0.0297,\n",
      "        0.0297, 0.0297, 0.0297, 0.0297, 0.0297, 0.0297, 0.0297, 0.0297, 0.0297,\n",
      "        0.0297, 0.0297, 0.0297, 0.0297, 0.0297, 0.0297, 0.0297, 0.0232, 0.0219,\n",
      "        0.0158, 0.0099, 0.0069, 0.0053, 0.0023, 0.0034, 0.0065, 0.0052, 0.0025,\n",
      "        0.0044, 0.0046])\n",
      "1.0 tensor([0.0787, 0.0481, 0.0322, 0.0322, 0.0322, 0.0322, 0.0322, 0.0322, 0.0322,\n",
      "        0.0322, 0.0322, 0.0322, 0.0322, 0.0322, 0.0322, 0.0322, 0.0322, 0.0322,\n",
      "        0.0322, 0.0322, 0.0322, 0.0322, 0.0322, 0.0322, 0.0322, 0.0176, 0.0226,\n",
      "        0.0109, 0.0115, 0.0087, 0.0100, 0.0114, 0.0075, 0.0071, 0.0069, 0.0062,\n",
      "        0.0071, 0.0050])\n",
      "0.8620268539916195 tensor([0.0230, 0.0315, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350,\n",
      "        0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350,\n",
      "        0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0345,\n",
      "        0.0224, 0.0147, 0.0090, 0.0104, 0.0033, 0.0039, 0.0041, 0.0004, 0.0003,\n",
      "        0.0002, 0.0014])\n",
      "1.0 tensor([0.1109, 0.0783, 0.0424, 0.0308, 0.0281, 0.0281, 0.0281, 0.0281, 0.0281,\n",
      "        0.0281, 0.0281, 0.0281, 0.0281, 0.0281, 0.0281, 0.0281, 0.0281, 0.0281,\n",
      "        0.0281, 0.0281, 0.0281, 0.0281, 0.0281, 0.0281, 0.0281, 0.0281, 0.0281,\n",
      "        0.0281, 0.0281, 0.0110, 0.0080, 0.0046, 0.0029, 0.0046, 0.0015, 0.0009,\n",
      "        0.0005, 0.0004])\n",
      "0.9955077463789068 tensor([0.2650, 0.1468, 0.0668, 0.0313, 0.0113, 0.0161, 0.0161, 0.0161, 0.0161,\n",
      "        0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0161,\n",
      "        0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0161,\n",
      "        0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0074, 0.0102, 0.0090, 0.0078,\n",
      "        0.0059, 0.0040])\n",
      "1.0 tensor([0.3357, 0.1547, 0.0444, 0.0389, 0.0329, 0.0135, 0.0135, 0.0135, 0.0135,\n",
      "        0.0135, 0.0135, 0.0135, 0.0135, 0.0135, 0.0135, 0.0135, 0.0135, 0.0135,\n",
      "        0.0135, 0.0135, 0.0135, 0.0135, 0.0135, 0.0135, 0.0135, 0.0135, 0.0135,\n",
      "        0.0135, 0.0135, 0.0135, 0.0135, 0.0135, 0.0084, 0.0079, 0.0070, 0.0030,\n",
      "        0.0007, 0.0010])\n",
      "1.0 tensor([0.1817, 0.0586, 0.0409, 0.0218, 0.0218, 0.0218, 0.0218, 0.0218, 0.0218,\n",
      "        0.0218, 0.0218, 0.0218, 0.0218, 0.0218, 0.0218, 0.0218, 0.0218, 0.0218,\n",
      "        0.0218, 0.0218, 0.0218, 0.0218, 0.0218, 0.0218, 0.0218, 0.0218, 0.0218,\n",
      "        0.0218, 0.0218, 0.0218, 0.0218, 0.0218, 0.0214, 0.0105, 0.0172, 0.0092,\n",
      "        0.0152, 0.0136])\n",
      "0.9991123865059319 tensor([0.2195, 0.0666, 0.0399, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203,\n",
      "        0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203,\n",
      "        0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203,\n",
      "        0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0210, 0.0101,\n",
      "        0.0056, 0.0068])\n",
      "0.9997148677067313 tensor([0.0374, 0.0337, 0.0306, 0.0271, 0.0277, 0.0259, 0.0256, 0.0256, 0.0256,\n",
      "        0.0256, 0.0256, 0.0256, 0.0256, 0.0256, 0.0255, 0.0255, 0.0255, 0.0255,\n",
      "        0.0255, 0.0255, 0.0255, 0.0255, 0.0256, 0.0255, 0.0255, 0.0255, 0.0255,\n",
      "        0.0255, 0.0255, 0.0255, 0.0255, 0.0255, 0.0255, 0.0255, 0.0255, 0.0255,\n",
      "        0.0255, 0.0255])\n",
      "0.9955873832041504 tensor([0.2825, 0.1149, 0.1309, 0.0743, 0.0549, 0.0516, 0.0365, 0.0273, 0.0291,\n",
      "        0.0131, 0.0142, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104,\n",
      "        0.0104, 0.0104, 0.0123, 0.0029, 0.0059, 0.0138, 0.0088, 0.0045, 0.0058,\n",
      "        0.0052, 0.0038, 0.0026, 0.0015, 0.0022, 0.0033, 0.0018, 0.0009, 0.0007,\n",
      "        0.0006, 0.0004])\n",
      "0.992088701050875 tensor([0.0553, 0.0525, 0.0545, 0.0545, 0.0545, 0.0545, 0.0545, 0.0545, 0.0545,\n",
      "        0.0545, 0.0545, 0.0545, 0.0545, 0.0545, 0.0545, 0.0168, 0.0054, 0.0203,\n",
      "        0.0031, 0.0124, 0.0166, 0.0173, 0.0122, 0.0142, 0.0035, 0.0091, 0.0016,\n",
      "        0.0056, 0.0038, 0.0132, 0.0022, 0.0021, 0.0066, 0.0030, 0.0021, 0.0043,\n",
      "        0.0018, 0.0065])\n",
      "0.9183574980868585 tensor([0.0482, 0.0741, 0.0571, 0.0571, 0.0571, 0.0571, 0.0571, 0.0571, 0.0571,\n",
      "        0.0571, 0.0571, 0.0571, 0.0571, 0.0571, 0.0571, 0.0373, 0.0003, 0.0162,\n",
      "        0.0007, 0.0102, 0.0203, 0.0030, 0.0009, 0.0024, 0.0128, 0.0013, 0.0029,\n",
      "        0.0080, 0.0039, 0.0029, 0.0016, 0.0030, 0.0016, 0.0016, 0.0022, 0.0009,\n",
      "        0.0011, 0.0010])\n",
      "0.9838075539009956 tensor([3.6971e-01, 1.5488e-01, 2.3694e-01, 1.1667e-01, 4.3185e-02, 4.8743e-03,\n",
      "        3.2720e-03, 3.2720e-03, 3.2720e-03, 3.2720e-03, 3.2720e-03, 3.2720e-03,\n",
      "        3.2720e-03, 3.2720e-03, 3.2720e-03, 3.2720e-03, 3.2720e-03, 3.2720e-03,\n",
      "        3.2720e-03, 3.2720e-03, 7.5523e-03, 8.0563e-03, 2.8292e-03, 2.0007e-03,\n",
      "        1.9154e-03, 1.0264e-03, 1.2196e-03, 6.4705e-04, 5.1686e-04, 6.9768e-04,\n",
      "        5.3722e-04, 5.1927e-04, 2.1058e-04, 9.5744e-05, 4.6603e-05, 2.1420e-05,\n",
      "        1.9434e-05, 1.3006e-05])\n",
      "0.9879425712940653 tensor([2.4591e-01, 1.6754e-01, 2.1081e-01, 1.8302e-01, 4.2067e-02, 1.5934e-02,\n",
      "        9.9354e-03, 6.2629e-03, 5.6332e-03, 5.6332e-03, 5.6332e-03, 5.6332e-03,\n",
      "        5.6332e-03, 5.6332e-03, 5.6332e-03, 5.6332e-03, 5.6332e-03, 5.6332e-03,\n",
      "        5.6332e-03, 5.6332e-03, 5.6332e-03, 5.6332e-03, 5.6332e-03, 1.2049e-02,\n",
      "        3.6925e-03, 2.8016e-03, 4.8149e-03, 5.5943e-03, 1.3151e-03, 1.0285e-03,\n",
      "        6.4304e-04, 5.4633e-04, 8.8182e-04, 3.4012e-04, 8.7142e-05, 1.4621e-04,\n",
      "        3.2355e-05, 4.8975e-05])\n",
      "0.990768941414658 tensor([0.1718, 0.0887, 0.1118, 0.0519, 0.0479, 0.0322, 0.0348, 0.0299, 0.0140,\n",
      "        0.0135, 0.0161, 0.0119, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "        0.0200, 0.0200, 0.0085, 0.0036, 0.0042, 0.0019, 0.0053, 0.0044, 0.0034,\n",
      "        0.0024, 0.0021])\n",
      "0.9699901627164128 tensor([0.2970, 0.0762, 0.1744, 0.1127, 0.0430, 0.0141, 0.0350, 0.0078, 0.0103,\n",
      "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
      "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
      "        0.0062, 0.0191, 0.0033, 0.0022, 0.0013, 0.0087, 0.0010, 0.0015, 0.0010,\n",
      "        0.0014, 0.0009])\n",
      "0.9997476566478455 tensor([0.1502, 0.1203, 0.0760, 0.0508, 0.0525, 0.0207, 0.0207, 0.0207, 0.0207,\n",
      "        0.0207, 0.0207, 0.0207, 0.0207, 0.0207, 0.0207, 0.0207, 0.0207, 0.0207,\n",
      "        0.0207, 0.0207, 0.0207, 0.0207, 0.0207, 0.0207, 0.0126, 0.0158, 0.0135,\n",
      "        0.0129, 0.0129, 0.0209, 0.0123, 0.0071, 0.0067, 0.0249, 0.0034, 0.0062,\n",
      "        0.0036, 0.0042])\n",
      "0.9881010472197954 tensor([0.0814, 0.0443, 0.0405, 0.0326, 0.0295, 0.0334, 0.0334, 0.0334, 0.0334,\n",
      "        0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334,\n",
      "        0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0263, 0.0214, 0.0138,\n",
      "        0.0191, 0.0112, 0.0071, 0.0064, 0.0097, 0.0051, 0.0043, 0.0027, 0.0041,\n",
      "        0.0018, 0.0038])\n",
      "0.9770279488325826 tensor([0.2469, 0.1070, 0.1827, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194,\n",
      "        0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194,\n",
      "        0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0046, 0.0100, 0.0060,\n",
      "        0.0108, 0.0041, 0.0071, 0.0027, 0.0015, 0.0011, 0.0021, 0.0017, 0.0010,\n",
      "        0.0011, 0.0014])\n",
      "1.0 tensor([0.1889, 0.1245, 0.0902, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243,\n",
      "        0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243,\n",
      "        0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0110, 0.0103,\n",
      "        0.0034, 0.0042, 0.0069, 0.0044, 0.0092, 0.0043, 0.0018, 0.0019, 0.0013,\n",
      "        0.0021, 0.0011])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.983520252040605"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_ndcg(pred.softmax(dim=1).detach().cpu().numpy(), b[1][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 34 is out of bounds for axis 0 with size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-464-04b57940c5b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 34 is out of bounds for axis 0 with size 32"
     ]
    }
   ],
   "source": [
    "b[1][:,:,0].numpy()[(-pred.softmax(dim=1).detach()).argsort().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.2898e-03, 3.4244e-03, 2.7234e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [3.7698e-02, 1.1295e-02, 1.0159e-02,  ..., 3.5411e-03, 3.5411e-03,\n",
       "         3.5411e-03],\n",
       "        [4.9808e-05, 4.9266e-05, 2.0854e-05,  ..., 2.1191e-04, 2.1191e-04,\n",
       "         2.1191e-04],\n",
       "        ...,\n",
       "        [3.2635e-02, 2.9457e-02, 4.0475e-02,  ..., 3.3415e-02, 3.3415e-02,\n",
       "         3.3415e-02],\n",
       "        [1.0017e-02, 2.7052e-03, 1.3543e-03,  ..., 1.9447e-02, 1.9447e-02,\n",
       "         1.9447e-02],\n",
       "        [1.0312e-02, 3.4165e-03, 2.1006e-03,  ..., 2.4301e-02, 2.4301e-02,\n",
       "         2.4301e-02]])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1][:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 34 is out of bounds for dimension 0 with size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-445-97053d2970c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 34 is out of bounds for dimension 0 with size 32"
     ]
    }
   ],
   "source": [
    "b[1][:,:,0][(-pred.softmax(dim=1).cpu().detach().numpy()).argsort(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 34 is out of bounds for dimension 0 with size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-432-97053d2970c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 34 is out of bounds for dimension 0 with size 32"
     ]
    }
   ],
   "source": [
    "b[1][:,:,0][(-pred.softmax(dim=1).cpu().detach().numpy()).argsort(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T22:22:48.706735Z",
     "start_time": "2019-08-21T22:22:48.663258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPU_ID': '-1',\n",
       " 'CUDA': False,\n",
       " 'WORKERS': 4,\n",
       " 'TRAIN': {'FLAG': True,\n",
       "  'LEARNING_RATE': 0.0001,\n",
       "  'BATCH_SIZE': 64,\n",
       "  'MAX_EPOCHS': 25,\n",
       "  'SNAPSHOT_INTERVAL': 5,\n",
       "  'WEIGHT_INIT': 'xavier_uniform',\n",
       "  'CLIP_GRADS': True,\n",
       "  'CLIP': 8,\n",
       "  'MAX_STEPS': 4,\n",
       "  'EALRY_STOPPING': True,\n",
       "  'PATIENCE': 5,\n",
       "  'VAR_DROPOUT': False},\n",
       " 'DATASET': {'DATA_DIR': '/Users/sebamenabar/Documents/datasets/CLEVR/data'}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T22:24:31.283196Z",
     "start_time": "2019-08-21T22:24:30.744351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, Sequential(\n",
      "  (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")), (1, Sequential(\n",
      "  (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")), (2, Sequential(\n",
      "  (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")), (3, Sequential(\n",
      "  (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "))]\n",
      "uno\n",
      "uno\n",
      "uno\n",
      "uno\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=['mac.control.attns.0.0.weight', 'mac.control.attns.0.0.bias', 'mac.control.attns.0.2.weight', 'mac.control.attns.0.2.bias', 'mac.control.attns.1.0.weight', 'mac.control.attns.1.0.bias', 'mac.control.attns.1.2.weight', 'mac.control.attns.1.2.bias', 'mac.control.attns.2.0.weight', 'mac.control.attns.2.0.bias', 'mac.control.attns.2.2.weight', 'mac.control.attns.2.2.bias', 'mac.control.attns.3.0.weight', 'mac.control.attns.3.0.bias', 'mac.control.attns.3.2.weight', 'mac.control.attns.3.2.bias'], unexpected_keys=['mac.control.concept_memory.categories', 'mac.control.concept_memory.attributes', 'mac.control.concept_memory.values'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.ATTNS_PATH = '/Users/sebamenabar/Documents/attn_preds.pth'\n",
    "model = MACNetwork(cfg=cfg, max_step=4, vocab=vocab)\n",
    "model.load_state_dict(torch.load('/Users/sebamenabar/Documents/vanilla_mac.pth', map_location='cpu')['model'], strict=False)\n",
    "# model(b['image'], b['question'], b['question_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T22:25:33.933167Z",
     "start_time": "2019-08-21T22:25:33.577433Z"
    }
   },
   "outputs": [],
   "source": [
    "whole_ds = ClevrDataset(\n",
    "    data_dir='/Users/sebamenabar/Documents/datasets/CLEVR/data',\n",
    "    # img_dir='/Users/sebamenabar/Documents/datasets/CLEVR/CLEVR_v1.0/images/',\n",
    "    # scenes_json='/Users/sebamenabar/Documents/TAIA/individual/sm/data/clevr/train/scenes.json',\n",
    "    # raw_image=True,\n",
    "    split='val',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T22:35:58.476664Z",
     "start_time": "2019-08-21T22:35:58.442443Z"
    }
   },
   "outputs": [],
   "source": [
    "whole_loader = DataLoader(whole_ds, batch_size=32, shuffle=False, collate_fn=whole_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T22:34:21.565066Z",
     "start_time": "2019-08-21T22:34:21.383090Z"
    }
   },
   "outputs": [],
   "source": [
    "b = next(iter(whole_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T14:43:43.002570Z",
     "start_time": "2019-08-21T22:45:48.424718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d592b18b5d240a0b30fb80c323aa35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4688), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-56ccd0381d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m# scores_ema = self.model_ema(image, question, question_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/ConceptMac/code/mac.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, question, question_len)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mquestion_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontextual_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0;31m# apply MacCell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontextual_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/ConceptMac/code/mac.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, question, question_len)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# get image features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(whole_loader, total=len(whole_loader))\n",
    "    total_accuracy = 0.\n",
    "    total_samples = 0\n",
    "    for data in pbar:\n",
    "\n",
    "        image, question, question_len, answer = data['image'], data['question'], data['question_length'], data['answer']\n",
    "        answer = answer.long()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            scores = model(image, question, question_len)\n",
    "            # scores_ema = self.model_ema(image, question, question_len)\n",
    "\n",
    "        # correct_ema = scores_ema.detach().argmax(1) == answer\n",
    "        # accuracy_ema = correct_ema.sum().cpu().numpy() / answer.shape[0]\n",
    "        # all_accuracies_ema.append(accuracy_ema)\n",
    "\n",
    "        correct = scores.detach().argmax(1) == answer\n",
    "        accuracy = correct.sum().cpu().numpy() / answer.shape[0]\n",
    "        # all_accuracies.append(accuracy)\n",
    "        total_accuracy += (accuracy * image.size(0))\n",
    "        total_samples += image.size(0)\n",
    "        \n",
    "        pbar.set_postfix(avg_accuracy=total_accuracy / total_samples)\n",
    "\n",
    "        # accuracy_ema = sum(all_accuracies_ema) / float(len(all_accuracies_ema))\n",
    "# accuracy = sum(all_accuracies) / float(len(all_accuracies))\n",
    "\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
