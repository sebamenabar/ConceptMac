{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalMemory(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_categories=4,\n",
    "                 num_attributes_per_category=5,\n",
    "                 categories_key_size=256,\n",
    "                 attributes_key_size=256,\n",
    "                 value_size=512,\n",
    "                 dropout=0.1,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_categories = num_categories\n",
    "        self.num_attributes_per_category = num_attributes_per_category\n",
    "        \n",
    "        self.categories_key_size = categories_key_size\n",
    "        self.attributes_key_size = attributes_key_size\n",
    "        self.value_size = value_size\n",
    "        \n",
    "        self.categories = torch.FloatTensor(num_categories, categories_key_size)\n",
    "        self.attributes = torch.FloatTensor(num_categories, num_attributes_per_category, attributes_key_size)\n",
    "        \n",
    "        self.categories = nn.Parameter(self.categories)\n",
    "        self.attributes = nn.Parameter(self.attributes)\n",
    "        \n",
    "        if value_size is not None:\n",
    "            self.values = torch.FloatTensor(num_categories, num_attributes_per_category, value_size)\n",
    "            self.values = nn.Parameter(self.values)\n",
    "        else:\n",
    "            self.values = None\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self._init_params()\n",
    "        \n",
    "    def _init_params(self):\n",
    "        nn.init.normal_(self.categories)\n",
    "        nn.init.normal_(self.attributes)\n",
    "        if self.values is not None:\n",
    "            nn.init.normal_(self.values)\n",
    "        \n",
    "    def forward(self, query):\n",
    "        \n",
    "        query = self.dropout(query)\n",
    "        category_attention = torch.matmul(query[:, :self.categories_key_size], self.categories.t())\n",
    "        category_attention = nn.functional.softmax(category_attention, dim=1)\n",
    "        \n",
    "        attribute_attention = torch.matmul(self.attributes, query[:, self.categories_key_size:].t())\n",
    "        attribute_attention = nn.functional.softmax(attribute_attention.permute(2, 0, 1), dim=2)\n",
    "        \n",
    "        category_values = torch.matmul(category_attention, self.categories)\n",
    "        if self.values is not None:\n",
    "            attribute_values = (attribute_attention.unsqueeze(3) * self.values).sum(dim=2)\n",
    "        else:\n",
    "            attribute_values = (attribute_attention.unsqueeze(3) * self.attributes).sum(dim=2)\n",
    "\n",
    "        values = torch.matmul(category_attention.unsqueeze(1), attribute_values).squeeze(1)\n",
    "        \n",
    "        return values, category_values, category_attention, attribute_attention \n",
    "\n",
    "    def get_category_attention(self, query):\n",
    "        category_attention = torch.matmul(query[:, :self.categories_key_size], self.categories.t())\n",
    "        category_attention = nn.functional.softmax(category_attention, dim=1)\n",
    "\n",
    "        return category_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm = HierarchicalMemory(3, 4, 5, 6, value_size=None)\n",
    "attributes, categories = hm.attributes, hm.categories\n",
    "# print(categories), print(attributes);\n",
    "hm(torch.ones(2, 11))[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mac'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3caf2af9a035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmac\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHierarchicalMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mac'"
     ]
    }
   ],
   "source": [
    "from mac import HierarchicalMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4126,  0.6920,  0.2098, -0.2235, -0.3082,  0.2059,  0.4995,\n",
       "           0.1840],\n",
       "         [-0.8027, -0.1491, -0.2894, -0.7281,  0.5694, -0.1165, -0.1300,\n",
       "          -0.0618],\n",
       "         [-0.5812,  1.0318, -0.1973, -0.1821, -0.3681, -0.3152, -0.9683,\n",
       "          -0.3389],\n",
       "         [ 0.3253,  0.0450, -0.0862, -0.0870, -0.3185,  0.1147,  0.0950,\n",
       "          -0.5925],\n",
       "         [ 0.4874, -0.6049, -0.0925,  0.0021,  0.3434,  0.9950, -0.0963,\n",
       "           0.3307]],\n",
       "\n",
       "        [[-0.4825, -0.1253, -0.1234, -0.1229,  0.3158, -0.5058, -0.2277,\n",
       "           0.6234],\n",
       "         [-1.0779, -0.6746, -0.4625,  0.3930, -0.2796, -0.1995, -0.3210,\n",
       "          -0.5292],\n",
       "         [-0.5685,  1.2189,  0.1967,  0.2939, -0.1047,  0.0913, -1.1220,\n",
       "          -0.4336],\n",
       "         [ 0.2339, -0.0343,  0.0202, -0.9019, -0.5439,  0.3890,  0.2416,\n",
       "          -0.6860],\n",
       "         [ 0.7302, -0.9310,  0.3548,  0.2108, -0.2683,  0.9025, -0.1845,\n",
       "           0.1122]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(nn.functional.softmax(torch.randn(2, 5, 6), dim=2).unsqueeze(3) *  torch.randn(5, 6, 8)).sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 11])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 4, 6])\n",
      "torch.Size([3, 4, 2])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1142, -0.0093,  1.2074,  0.8915, -0.6113,  0.2692],\n",
       "        [-0.0981,  1.2242, -0.0969,  0.5737,  0.4226, -0.1635]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchsummaryX import summary\n",
    "\n",
    "\n",
    "from mac import MACNetwork\n",
    "from utils import load_vocab\n",
    "from datasets import ClevrDataset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code/config.py:83: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "from config import cfg_from_file, __C, cfg\n",
    "\n",
    "cfg_from_file('cfg/local.yml')\n",
    "__C.CUDA = False\n",
    "__C.GPU_ID = '-1'\n",
    "vocab = load_vocab(cfg)\n",
    "# cfg.TRAIN.RECV_OBJECTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ClevrDataset(\n",
    "    data_dir='/Users/sebamenabar/Documents/datasets/CLEVR/data',\n",
    "    # img_dir='/Users/sebamenabar/Documents/datasets/CLEVR/CLEVR_v1.0/images/',\n",
    "    # scenes_json='/Users/sebamenabar/Documents/TAIA/individual/sm/data/clevr/train/scenes.json',\n",
    "    # raw_image=True,\n",
    "    split='val',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=ds, batch_size=2, shuffle=True,\n",
    "                                       num_workers=2, drop_last=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MACNetwork(cfg=cfg, max_step=4, vocab=vocab)\n",
    "model.load_state_dict(torch.load('/Users/sebamenabar/Documents/concept_mac.pth', map_location='cpu')['model'])\n",
    "# model(b['image'], b['question'], b['question_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 9.1099e-04, -5.2064e-02, -1.6987e-03,  6.7334e-04,  4.5890e-02,\n",
       "         -3.0428e-02,  5.2594e-02,  3.4504e-03,  1.2701e-02, -2.5365e-03,\n",
       "         -2.6305e-02,  4.4835e-02, -2.5110e-02,  6.1536e-02,  1.0283e-02,\n",
       "         -3.6328e-02,  1.7856e-03,  5.1706e-03,  1.5270e-01, -1.4143e-02,\n",
       "          7.4833e-03, -1.6326e-02,  1.1401e-03, -5.9885e-02,  1.3202e-03,\n",
       "          1.6604e-04,  9.7150e-03,  1.0755e-01,  5.1553e-02,  1.3866e-04,\n",
       "          4.2734e-02,  2.5243e-02, -2.5355e-02,  3.2289e-02,  2.3130e-02,\n",
       "          1.2027e-01, -2.9729e-02, -1.3794e-03, -6.0275e-02, -6.9985e-02,\n",
       "          9.5877e-02,  2.0320e-03, -2.1570e-03,  7.6947e-02,  3.5740e-02,\n",
       "          8.1291e-04, -2.9686e-02, -4.6840e-02, -9.4602e-04,  7.1419e-02,\n",
       "          1.5206e-01,  4.9460e-02, -7.8515e-05, -7.4855e-02, -3.1934e-03,\n",
       "         -4.4200e-02,  2.3165e-03, -1.8579e-03, -3.1161e-03,  3.0754e-04,\n",
       "         -3.7320e-02,  4.1890e-02, -1.1318e-01, -1.2373e-02, -9.0849e-02,\n",
       "          3.7740e-04,  1.1860e-02,  1.5363e-01, -1.1229e-04,  3.2262e-02,\n",
       "          2.5861e-02, -5.9563e-02, -2.0772e-02,  1.5880e-02,  1.4135e-01,\n",
       "          6.0121e-04, -1.3129e-01,  5.1138e-02,  1.2486e-01, -3.8959e-03,\n",
       "         -3.0881e-02, -8.1635e-02,  1.1924e-02, -1.3373e-01, -5.9992e-02,\n",
       "         -7.6826e-02,  1.2468e-01,  4.3019e-02, -3.3089e-03, -3.3863e-03,\n",
       "         -1.9630e-02,  1.6752e-01,  2.4405e-02,  3.6902e-03, -1.7098e-02,\n",
       "          1.2226e-01,  1.5189e-03, -3.2266e-03,  4.2841e-02,  1.5532e-04,\n",
       "          4.8680e-02,  2.0595e-02,  1.0633e-01,  1.3628e-01, -9.4412e-03,\n",
       "         -8.2744e-02, -1.7757e-03,  5.2393e-02,  2.1935e-01, -9.8130e-02,\n",
       "          1.3486e-03, -1.0791e-01, -1.1738e-03,  4.2353e-03,  1.0359e-01,\n",
       "          6.9969e-03, -6.6404e-02,  7.7633e-02, -9.7050e-04, -2.6686e-02,\n",
       "         -4.7344e-04,  1.6013e-02,  1.3166e-01, -5.5478e-04, -3.3327e-02,\n",
       "          8.8142e-02, -7.6547e-02, -5.0626e-02,  4.8910e-02,  8.9676e-02,\n",
       "         -2.5397e-03, -7.4061e-02,  8.0153e-02, -8.6310e-02,  2.6694e-02,\n",
       "         -5.2354e-02,  7.8780e-02,  4.9731e-02,  1.7113e-02, -2.5203e-03,\n",
       "         -1.5254e-01,  1.6740e-01,  4.0047e-02,  7.1905e-02,  2.4008e-03,\n",
       "         -4.9314e-02, -7.9241e-02, -3.2417e-02,  1.0299e-01,  1.9892e-02,\n",
       "         -1.7638e-01,  1.2738e-01,  1.0849e-01,  1.4505e-03, -3.9537e-02,\n",
       "          2.0213e-02,  2.9873e-02,  4.2331e-02,  1.4607e-03,  5.9642e-03,\n",
       "         -1.8600e-02,  5.3464e-02, -1.2489e-01,  7.4296e-03,  1.6713e-03,\n",
       "         -4.1226e-04,  2.4316e-02,  1.5375e-03, -1.7811e-02,  1.6787e-01,\n",
       "          6.1127e-03,  1.8697e-01,  5.2338e-03,  1.3392e-02, -6.9660e-02,\n",
       "          2.1856e-02, -1.0707e-01,  3.8515e-02,  1.8893e-02,  5.2415e-02,\n",
       "          1.2624e-01, -5.0572e-02, -1.2402e-02, -5.2375e-02,  7.8192e-03,\n",
       "          5.2459e-02, -1.3633e-01,  1.2397e-02, -1.0256e-01,  2.3231e-04,\n",
       "          1.4530e-01,  8.9229e-02,  4.1643e-04,  1.3255e-02,  3.4988e-02,\n",
       "          2.1373e-02, -2.6795e-02, -5.2107e-04,  2.6242e-03, -3.2543e-02,\n",
       "         -9.1701e-02, -5.3097e-02,  9.4611e-02,  6.9166e-02,  7.2136e-02,\n",
       "          1.0271e-01, -1.7197e-02, -2.8771e-03, -1.6369e-02, -4.6685e-02,\n",
       "         -5.3302e-02, -4.0301e-03,  1.9823e-02, -3.0975e-02,  4.0928e-04,\n",
       "         -2.3562e-04, -2.3513e-03,  3.9045e-03, -7.7506e-02, -1.3103e-01,\n",
       "          1.6334e-01, -7.1781e-02,  3.2120e-02,  1.7145e-02, -1.2672e-03,\n",
       "          1.1536e-02,  1.2035e-03, -3.0143e-03,  1.1666e-01, -3.7652e-03,\n",
       "          1.2625e-01,  4.1527e-02,  1.6088e-03,  6.1756e-04,  1.9403e-02,\n",
       "         -9.2921e-02, -3.0351e-02,  8.7662e-03, -8.1360e-02, -2.4571e-02,\n",
       "         -1.3083e-02, -2.9719e-02,  4.9091e-02, -6.1561e-04, -6.1678e-02,\n",
       "         -2.0335e-03,  1.9957e-02, -1.0742e-02,  1.7359e-03,  3.1953e-02,\n",
       "          7.6391e-02,  9.3370e-03, -9.4420e-02,  1.6457e-03, -2.4505e-03,\n",
       "          2.6212e-02, -4.8648e-03, -9.8589e-02, -1.5868e-02, -4.8551e-02,\n",
       "          1.6008e-02,  1.1902e-01, -1.7416e-03, -3.4956e-03,  4.3109e-04,\n",
       "         -1.2365e-01,  4.3015e-02,  2.8901e-02, -1.1762e-03,  2.4381e-02,\n",
       "         -1.6107e-03, -4.8601e-02,  7.3684e-03,  3.7001e-02, -3.8813e-02,\n",
       "         -2.0639e-02, -5.6477e-02,  1.1605e-02,  1.1343e-02, -3.9330e-03,\n",
       "         -3.2751e-04, -3.5093e-03, -6.0028e-04,  1.3090e-03,  1.6597e-03,\n",
       "          3.6534e-02, -1.2952e-02,  4.6660e-04, -2.7005e-02,  2.4708e-04,\n",
       "          1.2145e-03, -2.6180e-03,  3.0963e-02, -2.4023e-03,  7.0850e-03,\n",
       "          4.9653e-02, -1.2829e-02,  2.3720e-04, -1.6277e-04,  2.1648e-03,\n",
       "          9.7782e-03, -3.0750e-03, -1.0084e-02,  1.3563e-03, -9.3386e-04,\n",
       "         -1.8735e-03,  6.5295e-04, -3.1495e-03, -2.5947e-03, -6.2750e-03,\n",
       "          2.0494e-04,  4.4827e-02,  1.0032e-03, -7.1014e-04,  1.1215e-02,\n",
       "         -1.1333e-02, -1.7437e-03,  4.8427e-02, -1.0862e-01,  6.2379e-03,\n",
       "         -6.7269e-04, -4.3242e-04, -1.5631e-02, -1.8706e-04, -2.8836e-02,\n",
       "          3.2246e-03, -5.7500e-02,  4.3731e-02, -3.5726e-02, -2.0504e-03,\n",
       "         -7.5841e-02, -6.9792e-04,  2.3023e-02, -6.5831e-03, -3.9983e-02,\n",
       "          2.7831e-03,  1.0711e-03,  2.8738e-03,  5.2956e-04, -2.0112e-02,\n",
       "          5.8379e-02,  2.8423e-03,  2.8921e-03,  9.4179e-04, -6.6364e-04,\n",
       "         -2.9422e-03, -2.9695e-03, -8.8009e-04,  1.6434e-04, -1.9846e-03,\n",
       "          1.4399e-03, -2.0572e-02,  9.3657e-04, -2.3249e-03,  5.7440e-04,\n",
       "         -1.0565e-02,  2.8911e-02,  1.1447e-03, -1.5189e-03, -5.1116e-02,\n",
       "          1.5027e-03,  1.6331e-04,  1.5734e-04, -1.0280e-02, -1.9044e-02,\n",
       "         -1.4884e-02,  6.7186e-04,  3.4340e-02,  2.4762e-02, -2.2404e-03,\n",
       "          5.3277e-03,  1.0192e-03,  5.2591e-05, -8.4842e-04,  3.1265e-03,\n",
       "          3.9749e-03, -4.9364e-03, -2.8319e-03,  3.5201e-04, -3.7664e-03,\n",
       "         -2.2390e-03, -2.8133e-03,  1.7324e-03,  3.7516e-05,  3.3272e-03,\n",
       "         -3.4440e-03,  5.2700e-02, -7.1946e-04, -7.9540e-02,  1.2293e-03,\n",
       "          1.4019e-02,  4.9660e-02, -1.5330e-03,  7.2101e-04,  1.2928e-01,\n",
       "          2.2504e-03, -2.7043e-02, -2.9766e-02,  1.9656e-02, -7.7162e-02,\n",
       "          4.1646e-02, -3.1525e-03, -3.0855e-03, -2.1271e-04,  3.5895e-05,\n",
       "         -3.1895e-02,  1.2827e-04,  6.6536e-04, -2.7593e-03, -3.3680e-02,\n",
       "         -3.5555e-03,  1.1055e-04,  2.0479e-02, -2.8638e-03, -5.9633e-04,\n",
       "         -1.1106e-03, -6.7609e-03,  8.7271e-04, -9.0893e-02, -1.1812e-02,\n",
       "          1.6325e-03,  2.1918e-02,  4.1735e-03, -4.7689e-03, -1.0011e-03,\n",
       "         -1.3208e-03,  7.6799e-03,  6.1226e-04, -9.5439e-02, -6.1905e-02,\n",
       "         -4.8368e-06,  2.4522e-02, -5.7954e-02, -5.8108e-03, -1.1160e-02,\n",
       "          3.9085e-03,  1.0691e-03,  7.0462e-02, -4.5141e-04,  9.7293e-03,\n",
       "         -2.2077e-02, -1.4352e-02,  2.6457e-02, -9.2244e-02, -4.3484e-02,\n",
       "         -1.2532e-01, -2.3007e-04, -2.0810e-02, -5.9906e-04,  1.2268e-03,\n",
       "         -2.3077e-02,  2.0465e-03, -8.9376e-05, -2.0665e-02, -3.4513e-02,\n",
       "          3.9617e-04, -3.8707e-04, -1.7948e-03,  1.8583e-04,  3.0569e-02,\n",
       "         -1.4668e-02, -5.2336e-04, -3.8110e-02, -4.2506e-02, -9.3906e-05,\n",
       "          3.8268e-02, -3.0200e-04,  1.2102e-03,  1.9720e-03,  3.9292e-03,\n",
       "          5.8589e-04,  5.7093e-04, -2.4131e-02, -2.6281e-03,  2.5805e-03,\n",
       "         -4.6385e-04, -9.7995e-02,  7.4429e-02, -1.6094e-04, -4.1978e-03,\n",
       "         -4.8834e-03, -5.8903e-02, -4.8795e-02, -3.3999e-03, -1.9703e-04,\n",
       "          3.5544e-02, -3.3440e-04, -6.1802e-02,  1.7226e-04, -2.1497e-02,\n",
       "          1.5460e-02, -1.4550e-03, -3.2690e-03,  3.5484e-02,  4.0492e-03,\n",
       "          6.4732e-03, -1.0152e-03, -1.3841e-02, -4.2131e-04, -8.6863e-02,\n",
       "         -7.5630e-03, -5.0813e-03,  1.4634e-03,  3.8872e-04,  5.6939e-03,\n",
       "          1.0613e-01,  1.7778e-03,  5.3819e-04,  8.1963e-03,  1.9864e-04,\n",
       "         -9.8523e-02,  1.2952e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mac.control.attn.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
