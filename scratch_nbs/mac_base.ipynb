{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T14:07:38.485656Z",
     "start_time": "2019-09-10T14:07:38.453052Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T14:07:40.018832Z",
     "start_time": "2019-09-10T14:07:39.207991Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T14:07:40.054581Z",
     "start_time": "2019-09-10T14:07:40.022085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:29:21.076502Z",
     "start_time": "2019-08-31T01:29:21.031068Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## UTILS\n",
    "\n",
    "def load_vocab(cfg):\n",
    "    def invert_dict(d):\n",
    "        return {v: k for k, v in d.items()}\n",
    "\n",
    "    with open(os.path.join(cfg.DATASET.DATA_DIR, 'dic.pkl'), 'rb') as f:\n",
    "        dictionaries = pickle.load(f)\n",
    "    vocab = {}\n",
    "    vocab['question_token_to_idx'] = dictionaries[\"word_dic\"]\n",
    "    vocab['answer_token_to_idx'] = dictionaries[\"answer_dic\"]\n",
    "    vocab['question_token_to_idx']['pad'] = 0\n",
    "    vocab['question_idx_to_token'] = invert_dict(vocab['question_token_to_idx'])\n",
    "    vocab['answer_idx_to_token'] = invert_dict(vocab['answer_token_to_idx'])\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def init_modules(modules, w_init='kaiming_uniform'):\n",
    "    if w_init == \"normal\":\n",
    "        _init = init.normal_\n",
    "    elif w_init == \"xavier_normal\":\n",
    "        _init = init.xavier_normal_\n",
    "    elif w_init == \"xavier_uniform\":\n",
    "        _init = init.xavier_uniform_\n",
    "    elif w_init == \"kaiming_normal\":\n",
    "        _init = init.kaiming_normal_\n",
    "    elif w_init == \"kaiming_uniform\":\n",
    "        _init = init.kaiming_uniform_\n",
    "    elif w_init == \"orthogonal\":\n",
    "        _init = init.orthogonal_\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    for m in modules:\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
    "            _init(m.weight)\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "        if isinstance(m, (nn.LSTM, nn.GRU)):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'bias' in name:\n",
    "                    nn.init.zeros_(param)\n",
    "                elif 'weight' in name:\n",
    "                    _init(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:30:23.594012Z",
     "start_time": "2019-08-31T01:30:23.550543Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ControlUnit(nn.Module):\n",
    "    def __init__(self, cfg, module_dim, max_step=4):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.attn = nn.Linear(module_dim, 1)\n",
    "        self.control_input = nn.Sequential(nn.Linear(module_dim, module_dim),\n",
    "                                           nn.Tanh())\n",
    "\n",
    "        self.control_input_u = nn.ModuleList()\n",
    "        for i in range(max_step):\n",
    "            self.control_input_u.append(nn.Linear(module_dim, module_dim))\n",
    "\n",
    "        self.module_dim = module_dim\n",
    "\n",
    "    def mask(self, question_lengths, device):\n",
    "        max_len = max(question_lengths)\n",
    "        mask = torch.arange(max_len, device=device).expand(len(question_lengths), int(max_len)) < question_lengths.unsqueeze(1)\n",
    "        mask = mask.float()\n",
    "        ones = torch.ones_like(mask)\n",
    "        mask = (ones - mask) * (1e-30)\n",
    "        return mask\n",
    "\n",
    "    @staticmethod\n",
    "    def mask_by_length(x, lengths, device=None):\n",
    "        lengths = torch.as_tensor(lengths, dtype=torch.float32, device=device)\n",
    "        max_len = max(lengths)\n",
    "        mask = torch.arange(max_len, device=device).expand(len(lengths), int(max_len)) < lengths.unsqueeze(1)\n",
    "        mask = mask.float().unsqueeze(2)\n",
    "        x_masked = x * mask + (1 - 1 / mask)\n",
    "\n",
    "        return x_masked\n",
    "\n",
    "    def forward(self, question, context, question_lengths, step):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            question: external inputs to control unit (the question vector).\n",
    "                [batchSize, ctrlDim]\n",
    "            context: the representation of the words used to compute the attention.\n",
    "                [batchSize, questionLength, ctrlDim]\n",
    "            control: previous control state\n",
    "            question_lengths: the length of each question.\n",
    "                [batchSize]\n",
    "            step: which step in the reasoning chain\n",
    "        \"\"\"\n",
    "        # compute interactions with question words\n",
    "        question = self.control_input(question)\n",
    "        question = self.control_input_u[step](question)\n",
    "\n",
    "        newContControl = question\n",
    "        newContControl = torch.unsqueeze(newContControl, 1)\n",
    "        interactions = newContControl * context\n",
    "\n",
    "        # compute attention distribution over words and summarize them accordingly\n",
    "        logits = self.attn(interactions)\n",
    "\n",
    "        logits = self.mask_by_length(logits, question_lengths, device=context.device)\n",
    "        attn = F.softmax(logits, 1)\n",
    "\n",
    "        # apply soft attention to current context words\n",
    "        next_control = (attn * context).sum(1)\n",
    "\n",
    "        return next_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:31:09.358302Z",
     "start_time": "2019-08-31T01:31:09.311188Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ReadUnit(nn.Module):\n",
    "    def __init__(self, module_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.concat = nn.Linear(module_dim * 2, module_dim)\n",
    "        self.concat_2 = nn.Linear(module_dim, module_dim)\n",
    "        self.attn = nn.Linear(module_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        self.kproj = nn.Linear(module_dim, module_dim)\n",
    "        self.mproj = nn.Linear(module_dim, module_dim)\n",
    "\n",
    "        self.activation = nn.ELU()\n",
    "        self.module_dim = module_dim\n",
    "\n",
    "    def forward(self, memory, know, control, memDpMask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            memory: the cell's memory state\n",
    "                [batchSize, memDim]\n",
    "\n",
    "            know: representation of the knowledge base (image).\n",
    "                [batchSize, kbSize (Height * Width), memDim]\n",
    "\n",
    "            control: the cell's control state\n",
    "                [batchSize, ctrlDim]\n",
    "\n",
    "            memDpMask: variational dropout mask (if used)\n",
    "                [batchSize, memDim]\n",
    "        \"\"\"\n",
    "        ## Step 1: knowledge base / memory interactions\n",
    "        # compute interactions between knowledge base and memory\n",
    "        know = self.dropout(know)\n",
    "        if memDpMask is not None:\n",
    "            if self.training:\n",
    "                memory = applyVarDpMask(memory, memDpMask, 0.85)\n",
    "        else:\n",
    "            memory = self.dropout(memory)\n",
    "        know_proj = self.kproj(know)\n",
    "        memory_proj = self.mproj(memory)\n",
    "        memory_proj = memory_proj.unsqueeze(1)\n",
    "        interactions = know_proj * memory_proj\n",
    "\n",
    "        # project memory interactions back to hidden dimension\n",
    "        interactions = torch.cat([interactions, know_proj], -1)\n",
    "        interactions = self.concat(interactions)\n",
    "        interactions = self.activation(interactions)\n",
    "        interactions = self.concat_2(interactions)\n",
    "\n",
    "        ## Step 2: compute interactions with control\n",
    "        control = control.unsqueeze(1)\n",
    "        interactions = interactions * control\n",
    "        interactions = self.activation(interactions)\n",
    "\n",
    "        ## Step 3: sum attentions up over the knowledge base\n",
    "        # transform vectors to attention distribution\n",
    "        interactions = self.dropout(interactions)\n",
    "        attn = self.attn(interactions).squeeze(-1)\n",
    "        attn = F.softmax(attn, 1)\n",
    "\n",
    "        # sum up the knowledge base according to the distribution\n",
    "        attn = attn.unsqueeze(-1)\n",
    "        read = (attn * know).sum(1)\n",
    "\n",
    "        return read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:31:10.317750Z",
     "start_time": "2019-08-31T01:31:10.286985Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class WriteUnit(nn.Module):\n",
    "    def __init__(self, cfg, module_dim):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.linear = nn.Linear(module_dim * 2, module_dim)\n",
    "\n",
    "    def forward(self, memory, info):\n",
    "        # newMemory = torch.cat([memory, info], -1)\n",
    "        # newMemory = self.linear(newMemory)\n",
    "        newMemory = info\n",
    "\n",
    "        return newMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:31:38.107753Z",
     "start_time": "2019-08-31T01:31:38.071059Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MACUnit(nn.Module):\n",
    "    def __init__(self, cfg, module_dim=512, max_step=4):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.control = ControlUnit(cfg, module_dim, max_step)\n",
    "        self.read = ReadUnit(module_dim)\n",
    "        self.write = WriteUnit(cfg, module_dim)\n",
    "\n",
    "        self.initial_memory = nn.Parameter(torch.zeros(1, module_dim))\n",
    "\n",
    "        self.module_dim = module_dim\n",
    "        self.max_step = max_step\n",
    "\n",
    "    def zero_state(self, batch_size, question):\n",
    "        initial_memory = self.initial_memory.expand(batch_size, self.module_dim)\n",
    "        initial_control = question\n",
    "\n",
    "        if self.cfg.TRAIN.VAR_DROPOUT:\n",
    "            memDpMask = generateVarDpMask((batch_size, self.module_dim), 0.85)\n",
    "        else:\n",
    "            memDpMask = None\n",
    "\n",
    "        return initial_control, initial_memory, memDpMask\n",
    "\n",
    "    def forward(self, context, question, knowledge, question_lengths):\n",
    "        batch_size = question.size(0)\n",
    "        control, memory, memDpMask = self.zero_state(batch_size, question)\n",
    "\n",
    "        for i in range(self.max_step):\n",
    "            # control unit\n",
    "            control = self.control(question, context, question_lengths, i)\n",
    "            # read unit\n",
    "            info = self.read(memory, knowledge, control, memDpMask)\n",
    "            # write unit\n",
    "            memory = self.write(memory, info)\n",
    "\n",
    "        return memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:31:54.740969Z",
     "start_time": "2019-08-31T01:31:54.694723Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class InputUnit(nn.Module):\n",
    "    def __init__(self, cfg, vocab_size, wordvec_dim=300, rnn_dim=512, module_dim=512, bidirectional=True):\n",
    "        super(InputUnit, self).__init__()\n",
    "\n",
    "        self.dim = module_dim\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.stem = nn.Sequential(nn.Dropout(p=0.18),\n",
    "                                  nn.Conv2d(1024, module_dim, 3, 1, 1),\n",
    "                                  nn.ELU(),\n",
    "                                  nn.Dropout(p=0.18),\n",
    "                                  nn.Conv2d(module_dim, module_dim, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ELU())\n",
    "\n",
    "        self.bidirectional = bidirectional\n",
    "        if bidirectional:\n",
    "            rnn_dim = rnn_dim // 2\n",
    "\n",
    "        self.encoder_embed = nn.Embedding(vocab_size, wordvec_dim)\n",
    "        self.encoder = nn.LSTM(wordvec_dim, rnn_dim, batch_first=True, bidirectional=bidirectional)\n",
    "        self.embedding_dropout = nn.Dropout(p=0.15)\n",
    "        self.question_dropout = nn.Dropout(p=0.08)\n",
    "\n",
    "    def forward(self, image, question, question_len):\n",
    "        b_size = question.size(0)\n",
    "\n",
    "        # get image features\n",
    "        img = self.stem(image)\n",
    "        img = img.view(b_size, self.dim, -1)\n",
    "        img = img.permute(0,2,1)\n",
    "\n",
    "        # get question and contextual word embeddings\n",
    "        embed = self.encoder_embed(question)\n",
    "        embed = self.embedding_dropout(embed)\n",
    "        embed = nn.utils.rnn.pack_padded_sequence(embed, question_len, batch_first=True)\n",
    "\n",
    "        contextual_words, (question_embedding, _) = self.encoder(embed)\n",
    "        if self.bidirectional:\n",
    "            question_embedding = torch.cat([question_embedding[0], question_embedding[1]], -1)\n",
    "        question_embedding = self.question_dropout(question_embedding)\n",
    "\n",
    "        contextual_words, _ = nn.utils.rnn.pad_packed_sequence(contextual_words, batch_first=True)\n",
    "\n",
    "        return question_embedding, contextual_words, img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:32:05.777337Z",
     "start_time": "2019-08-31T01:32:05.742277Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class OutputUnit(nn.Module):\n",
    "    def __init__(self, module_dim=512, num_answers=28):\n",
    "        super(OutputUnit, self).__init__()\n",
    "\n",
    "        self.question_proj = nn.Linear(module_dim, module_dim)\n",
    "\n",
    "        self.classifier = nn.Sequential(nn.Dropout(0.15),\n",
    "                                        nn.Linear(module_dim * 2, module_dim),\n",
    "                                        nn.ELU(),\n",
    "                                        nn.Dropout(0.15),\n",
    "                                        nn.Linear(module_dim, num_answers))\n",
    "\n",
    "    def forward(self, question_embedding, memory):\n",
    "        # apply classifier to output of MacCell and the question\n",
    "        question_embedding = self.question_proj(question_embedding)\n",
    "        out = torch.cat([memory, question_embedding], 1)\n",
    "        out = self.classifier(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:32:32.845266Z",
     "start_time": "2019-08-31T01:32:32.809171Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MACNetwork(nn.Module):\n",
    "    def __init__(self, cfg, max_step, vocab):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "        encoder_vocab_size = len(vocab['question_token_to_idx'])\n",
    "\n",
    "        self.input_unit = InputUnit(cfg, vocab_size=encoder_vocab_size)\n",
    "\n",
    "        self.output_unit = OutputUnit()\n",
    "\n",
    "        self.mac = MACUnit(cfg, max_step=max_step)\n",
    "\n",
    "        init_modules(self.modules(), w_init=self.cfg.TRAIN.WEIGHT_INIT)\n",
    "        nn.init.uniform_(self.input_unit.encoder_embed.weight, -1.0, 1.0)\n",
    "        nn.init.normal_(self.mac.initial_memory)\n",
    "\n",
    "    def forward(self, image, question, question_len):\n",
    "        # get image, word, and sentence embeddings\n",
    "        question_embedding, contextual_words, img = self.input_unit(image, question, question_len)\n",
    "\n",
    "        # apply MacCell\n",
    "        memory = self.mac(contextual_words, question_embedding, img, question_len)\n",
    "\n",
    "        # get classification\n",
    "        out = self.output_unit(question_embedding, memory)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:34:28.303758Z",
     "start_time": "2019-08-31T01:34:28.265499Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = edict({\n",
    "    'GPU_ID': '-1',\n",
    "    'CUDA': False,\n",
    "    'WORKERS': 4,\n",
    "    'TRAIN': {'FLAG': True,\n",
    "    'LEARNING_RATE': 0.0001,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'MAX_EPOCHS': 25,\n",
    "    'SNAPSHOT_INTERVAL': 5,\n",
    "    'WEIGHT_INIT': 'xavier_uniform',\n",
    "    'CLIP_GRADS': True,\n",
    "    'CLIP': 8,\n",
    "    'MAX_STEPS': 4,\n",
    "    'EALRY_STOPPING': True,\n",
    "    'PATIENCE': 5,\n",
    "    'VAR_DROPOUT': False},\n",
    "    'DATASET': {\n",
    "        # 'DATA_DIR': '/mnt/nas2/GrimaRepo/datasets/CLEVR_v1.0/features',\n",
    "        'DATA_DIR': '/Users/sebamenabar/Documents/datasets/CLEVR/data/',\n",
    "    }\n",
    "})\n",
    "\n",
    "vocab = load_vocab(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:35:49.213317Z",
     "start_time": "2019-08-31T01:35:49.168177Z"
    },
    "code_folding": [
     0,
     19
    ]
   },
   "outputs": [],
   "source": [
    "class ClevrDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, split='train'):\n",
    "\n",
    "        with open(os.path.join(data_dir, '{}.pkl'.format(split)), 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "        # self.img = h5py.File(os.path.join(data_dir, '{}_features.h5'.format(split)), 'r')['features'] # ['data']\n",
    "        self.img = h5py.File(os.path.join(data_dir, '{}_features.hdf5'.format(split)), 'r')['data']\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imgfile, question, answer, family = self.data[index]\n",
    "        id = int(imgfile.rsplit('_', 1)[1][:-4])\n",
    "        img = torch.from_numpy(self.img[id])\n",
    "\n",
    "        return img, question, len(question), answer, family\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, lengths, answers, _ = [], [], [], []\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    max_len = max(map(lambda x: len(x[1]), batch))\n",
    "\n",
    "    questions = np.zeros((batch_size, max_len), dtype=np.int64)\n",
    "    sort_by_len = sorted(batch, key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "    for i, b in enumerate(sort_by_len):\n",
    "        image, question, length, answer, family = b\n",
    "        images.append(image)\n",
    "        length = len(question)\n",
    "        questions[i, :length] = question\n",
    "        lengths.append(length)\n",
    "        answers.append(answer)\n",
    "\n",
    "    return {'image': torch.stack(images), 'question': torch.from_numpy(questions),\n",
    "            'answer': torch.LongTensor(answers), 'question_length': lengths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MACNetwork(cfg=cfg, max_step=4, vocab=vocab)\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
